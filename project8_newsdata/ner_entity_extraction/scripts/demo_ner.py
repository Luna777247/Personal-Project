#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NER Entity Extraction Demo
Demonstration of Named Entity Recognition for Disaster Information
Uses real data from disaster_data_multisource_20251207_165113.json

This script demonstrates the usage of different NER models for extracting
disaster-related entities from Vietnamese news articles.
"""

import logging
import json
import os
import time
from typing import List, Dict, Any
import sys
from pathlib import Path

# Add parent directory to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config.nlp_config import MODEL_CONFIGS, EXTRACTION_CONFIG
from .phoner_extractor import PhoNERExtractor
from .vncorenlp_extractor import VnCoreNLPExtractor
from .spacy_custom_extractor import SpacyCustomExtractor
from .bert_ner_extractor import BERTNERExtractor

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def load_sample_articles() -> List[Dict[str, Any]]:
    """
    Load real disaster data from JSON file
    
    Returns:
        List[Dict[str, Any]]: List of articles
    """
    try:
        # Try to load real data
        sys.path.insert(0, str(Path(__file__).parent.parent.parent))
        from real_data_loader import load_real_disaster_data, convert_to_articles
        
        records = load_real_disaster_data(limit=10)
        articles = convert_to_articles(records)
        logger.info(f"âœ… Loaded {len(articles)} real articles from JSON")
        return articles
    except Exception as e:
        logger.warning(f"Could not load real data: {e}")
        logger.info("Using fallback sample articles...")
        return load_sample_articles_fallback()

def load_sample_articles_fallback() -> List[Dict[str, Any]]:
    """
    Load fallback sample articles
    """
    return [
        {
            "title": "BÃ£o sá»‘ 9 gÃ¢y thiá»‡t háº¡i náº·ng táº¡i cÃ¡c tá»‰nh miá»n Trung",
            "content": """BÃ£o sá»‘ 9 Ä‘Ã£ Ä‘á»• bá»™ vÃ o cÃ¡c tá»‰nh miá»n Trung vÃ o sÃ¡ng ngÃ y 12/11,
            gÃ¢y giÃ³ máº¡nh cáº¥p 12-13, sÃ³ng biá»ƒn cao 5-7m. HÃ ng trÄƒm ngÃ´i nhÃ  bá»‹ tá»‘c mÃ¡i,
            nhiá»u diá»‡n tÃ­ch lÃºa bá»‹ ngáº­p Ãºng. Theo bÃ¡o cÃ¡o sÆ¡ bá»™ cá»§a Ban chá»‰ huy phÃ²ng
            chá»‘ng thiÃªn tai tá»‰nh Quáº£ng Nam, cÃ³ 3 ngÆ°á»i cháº¿t, 10 ngÆ°á»i bá»‹ thÆ°Æ¡ng.
            Thiá»‡t háº¡i ban Ä‘áº§u Æ°á»›c tÃ­nh 500 tá»· Ä‘á»“ng.""",
            "url": "https://vnexpress.net/bao-so-9-gay-thiet-hai-nang-123456",
            "source": "vnexpress"
        },
        {
            "title": "Äá»™ng Ä‘áº¥t máº¡nh 6.5 Ä‘á»™ Richter táº¡i Kon Tum",
            "content": """SÃ¡ng nay 15/8, má»™t tráº­n Ä‘á»™ng Ä‘áº¥t máº¡nh 6.5 Ä‘á»™ Richter Ä‘Ã£ xáº£y ra
            táº¡i huyá»‡n Kon PlÃ´ng, tá»‰nh Kon Tum. Theo Trung tÃ¢m bÃ¡o tin Ä‘á»™ng Ä‘áº¥t vÃ 
            cáº£nh bÃ¡o sÃ³ng tháº§n, tÃ¢m cháº¥n náº±m á»Ÿ phÆ°á»ng TrÆ°á»ng Chinh, thÃ nh phá»‘ Kon Tum,
            Ä‘á»™ sÃ¢u khoáº£ng 10km. NgÆ°á»i dÃ¢n Ä‘á»‹a phÆ°Æ¡ng cho biáº¿t cáº£m nháº­n Ä‘Æ°á»£c rung láº¯c
            máº¡nh khoáº£ng 10-15 giÃ¢y. Hiá»‡n chÆ°a cÃ³ bÃ¡o cÃ¡o vá» thiá»‡t háº¡i.""",
            "url": "https://dantri.com.vn/Ä‘á»™ng-Ä‘áº¥t-kon-tum-123456",
            "source": "dantri"
        },
        {
            "title": "LÅ© quÃ©t táº¡i Gia Lai lÃ m 5 ngÆ°á»i máº¥t tÃ­ch",
            "content": """MÆ°a lá»›n kÃ©o dÃ i nhiá»u ngÃ y qua Ä‘Ã£ gÃ¢y lÅ© quÃ©t táº¡i xÃ£ Ia Pal,
            huyá»‡n ChÆ° PrÃ´ng, tá»‰nh Gia Lai. Theo Ã´ng Nguyá»…n VÄƒn BÃ¬nh, GiÃ¡m Ä‘á»‘c Sá»Ÿ TÃ i
            nguyÃªn vÃ  MÃ´i trÆ°á»ng Gia Lai, lÅ© quÃ©t Ä‘Ã£ cuá»‘n trÃ´i 3 ngÃ´i nhÃ , lÃ m 5 ngÆ°á»i
            máº¥t tÃ­ch. Äá»™i cá»©u há»™ Ä‘Ã£ Ä‘Æ°á»£c triá»ƒn khai Ä‘áº¿n hiá»‡n trÆ°á»ng. NguyÃªn nhÃ¢n ban Ä‘áº§u
            Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh lÃ  do mÆ°a lá»›n káº¿t há»£p vá»›i Ä‘á»‹a hÃ¬nh nÃºi rá»«ng.""",
            "url": "https://tuoitre.vn/lu-quet-gia-lai-123456",
            "source": "tuoitre"
        }
    ]

def create_extractor(model_name: str) -> Any:
    """
    Create NER extractor instance

    Args:
        model_name: Name of the model to create

    Returns:
        NERExtractor instance or None
    """
    if model_name not in MODEL_CONFIGS:
        logger.error(f"Unknown model: {model_name}")
        return None

    config = MODEL_CONFIGS[model_name].copy()
    config.update(EXTRACTION_CONFIG)

    try:
        if model_name == "phoner":
            return PhoNERExtractor(config)
        elif model_name == "vncorenlp":
            return VnCoreNLPExtractor(config)
        elif model_name == "spacy_custom":
            return SpacyCustomExtractor(config)
        elif model_name == "bert_ner":
            return BERTNERExtractor(config)
        else:
            logger.error(f"Unsupported model: {model_name}")
            return None
    except Exception as e:
        logger.error(f"Failed to create {model_name} extractor: {str(e)}")
        return None

def run_model_demo(model_name: str, articles: List[Dict[str, Any]]) -> None:
    """
    Run demo for a specific NER model

    Args:
        model_name: Name of the model to test
        articles: List of articles to process
    """
    logger.info(f"\nðŸš€ Testing {model_name.upper()} Model")
    logger.info("=" * 60)

    # Create extractor
    extractor = create_extractor(model_name)
    if not extractor:
        logger.error(f"Failed to create {model_name} extractor")
        return

    # Load model
    if not extractor.load_model():
        logger.error(f"Failed to load {model_name} model")
        return

    # Process articles
    start_time = time.time()
    results = extractor.process_batch(articles)
    total_time = time.time() - start_time

    # Display results
    logger.info(f"\nðŸ“Š {model_name.upper()} RESULTS SUMMARY:")
    logger.info(f"   Total articles processed: {len(results)}")
    logger.info(f"   Total entities extracted: {sum(len(r.entities) for r in results)}")
    logger.info(f"   Total processing time: {total_time:.2f} seconds")
    logger.info(f"   Average time per article: {total_time/len(results):.2f} seconds")

    # Display detailed results
    for i, result in enumerate(results, 1):
        logger.info(f"\nðŸ“„ Article {i}: {result.article_title[:50]}...")
        logger.info(f"   Source: {result.article_source}")
        logger.info(f"   Entities found: {len(result.entities)}")
        logger.info(f"   Processing time: {result.processing_time:.2f}s")
        logger.info(f"   Confidence score: {result.confidence_score:.2f}")

        if result.entities:
            logger.info("   ðŸ“‹ Extracted Entities:")
            for entity in result.entities[:5]:  # Show first 5 entities
                logger.info(f"      â€¢ {entity.label}: '{entity.text}' (conf: {entity.confidence:.2f})")
            if len(result.entities) > 5:
                logger.info(f"      ... and {len(result.entities) - 5} more entities")
        else:
            logger.info("   âŒ No entities extracted")

    # Save results
    output_dir = "data"
    os.makedirs(output_dir, exist_ok=True)

    json_path = os.path.join(output_dir, f"ner_{model_name}_demo.json")
    csv_path = os.path.join(output_dir, f"ner_{model_name}_demo.csv")

    extractor.save_results(results, json_path)
    extractor.save_csv_results(results, csv_path)

    logger.info(f"\nðŸ’¾ Results saved:")
    logger.info(f"   JSON: {json_path}")
    logger.info(f"   CSV: {csv_path}")

def run_comparison_demo(articles: List[Dict[str, Any]]) -> None:
    """
    Run comparison demo across all models

    Args:
        articles: List of articles to process
    """
    logger.info("\nðŸ”„ COMPARISON ACROSS ALL MODELS")
    logger.info("=" * 80)

    model_names = ["phoner", "vncorenlp", "spacy_custom", "bert_ner"]
    comparison_results = {}

    for model_name in model_names:
        logger.info(f"\nðŸ§ª Testing {model_name.upper()}...")

        extractor = create_extractor(model_name)
        if not extractor:
            logger.warning(f"Skipping {model_name} - failed to create")
            continue

        if not extractor.load_model():
            logger.warning(f"Skipping {model_name} - failed to load model")
            continue

        start_time = time.time()
        results = extractor.process_batch(articles)
        total_time = time.time() - start_time

        total_entities = sum(len(r.entities) for r in results)
        avg_confidence = sum(r.confidence_score for r in results) / len(results) if results else 0

        comparison_results[model_name] = {
            "articles_processed": len(results),
            "total_entities": total_entities,
            "total_time": total_time,
            "avg_time_per_article": total_time / len(results) if results else 0,
            "avg_confidence": avg_confidence,
            "entities_per_article": total_entities / len(results) if results else 0
        }

        logger.info(f"   âœ… {model_name.upper()}: {total_entities} entities, {total_time:.2f}s, conf: {avg_confidence:.2f}")

    # Display comparison table
    logger.info(f"\nðŸ“Š MODEL COMPARISON TABLE:")
    logger.info("-" * 100)
    logger.info("<20")
    logger.info("-" * 100)

    for model_name, stats in comparison_results.items():
        logger.info("<20")

    logger.info("-" * 100)

def main():
    """Main demo function"""
    logger.info("ðŸš€ NER Entity Extraction Demo")
    logger.info("Named Entity Recognition for Disaster Information")
    logger.info("=" * 80)

    # Load sample articles
    articles = load_sample_articles()
    logger.info(f"ðŸ“š Loaded {len(articles)} sample disaster articles")

    # Run individual model demos
    model_names = ["phoner", "vncorenlp", "spacy_custom", "bert_ner"]

    for model_name in model_names:
        try:
            run_model_demo(model_name, articles)
        except Exception as e:
            logger.error(f"Error testing {model_name}: {str(e)}")
            continue

    # Run comparison
    try:
        run_comparison_demo(articles)
    except Exception as e:
        logger.error(f"Error in comparison demo: {str(e)}")

    logger.info("\nðŸŽ‰ Demo completed!")
    logger.info("Check the 'data/' directory for output files")
    logger.info("Each model generates JSON and CSV results")

if __name__ == "__main__":
    main()
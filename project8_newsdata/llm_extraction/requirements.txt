# LLM-Based Extraction Requirements
# Dependencies for Large Language Model-based extraction

# Core LLM libraries
openai>=1.0.0          # OpenAI API (GPT-3.5, GPT-4)
anthropic>=0.7.0       # Anthropic Claude API
groq>=0.4.0           # Groq API (fast Llama models)

# Data processing and utilities
pandas>=1.5.0
numpy>=1.21.0
requests>=2.28.0
python-dotenv>=1.0.0   # Environment variables

# JSON schema validation
jsonschema>=4.0.0
pydantic>=2.0.0        # Data validation

# Vietnamese NLP processing
underthesea>=1.3.0
pyvi>=0.1.1

# Utilities and async support
tqdm>=4.64.0
colorama>=0.4.6
asyncio-mqtt>=0.11.0   # Optional for async processing
aiohttp>=3.8.0         # Async HTTP requests

# Caching and rate limiting
cachetools>=5.0.0
ratelimit>=2.2.0

# Development and testing
pytest>=7.0.0
pytest-asyncio>=0.21.0
black>=22.0.0
flake8>=5.0.0

# Optional: Local LLM support
# transformers>=4.21.0
# torch>=1.12.0
# accelerate>=0.20.0

# Optional: For advanced prompt engineering
# langchain>=0.0.200
# llama-index>=0.8.0
# LLM-Based Disaster Information Extraction - Environment Variables

# Copy this file to .env and fill in your API keys

# OpenAI API Configuration
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic API Configuration
# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Groq API Configuration
# Get your API key from: https://console.groq.com/keys
GROQ_API_KEY=your_groq_api_key_here

# Optional: Cost Management
# Set budget limits (in USD) to prevent unexpected costs
LLM_EXTRACTION_BUDGET_LIMIT=10.0
LLM_EXTRACTION_DAILY_BUDGET=2.0

# Optional: Performance Settings
# Cache settings
LLM_CACHE_TTL_SECONDS=3600
LLM_CACHE_MAX_SIZE=1000

# Rate limiting
LLM_RATE_LIMIT_REQUESTS_PER_MINUTE=60

# Optional: Logging
# Set to DEBUG for detailed logs, INFO for normal operation
LOG_LEVEL=INFO

# Optional: Model Preferences
# Default model to use (will fallback to cheaper models if unavailable/cost exceeded)
DEFAULT_LLM_MODEL=gpt-3.5-turbo

# Optional: Vietnamese NLP Settings
# UnderTheSea model for Vietnamese text preprocessing
UNDERSEA_MODEL=TCBank

# Optional: Output Settings
# Default output format (json or csv)
DEFAULT_OUTPUT_FORMAT=json

# Optional: API Timeouts (in seconds)
LLM_API_TIMEOUT=30
LLM_API_MAX_RETRIES=3
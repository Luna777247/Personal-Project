{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f5a9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# YOLOv8 and custom modules\n",
    "from ultralytics import YOLO\n",
    "from src.yolov8_detector import YOLOv8Detector, create_data_yaml\n",
    "from src.data_preprocessing import YOLODataPreprocessor\n",
    "from src.evaluation import YOLOEvaluator\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dafd505",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "Configure the workspace and check available resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9292ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'model_size': 'yolov8n',  # n, s, m, l, x\n",
    "    'device': 'auto',  # auto, cpu, cuda\n",
    "    'data_dir': 'data',\n",
    "    'runs_dir': 'runs',\n",
    "    'batch_size': 16,\n",
    "    'epochs': 50,\n",
    "    'img_size': 640,\n",
    "    'conf_threshold': 0.25,\n",
    "    'iou_threshold': 0.6\n",
    "}\n",
    "\n",
    "# Create directories\n",
    "for dir_name in [CONFIG['data_dir'], CONFIG['runs_dir']]:\n",
    "    Path(dir_name).mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Check GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\nGPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"\\nRunning on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354cb80a",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "Prepare your dataset for YOLOv8 training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e07d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data preprocessor\n",
    "preprocessor = YOLODataPreprocessor(CONFIG['data_dir'])\n",
    "\n",
    "# Define your classes\n",
    "CLASSES = ['person', 'car', 'truck', 'bus', 'motorcycle', 'bicycle']\n",
    "\n",
    "print(f\"Classes: {CLASSES}\")\n",
    "print(f\"Number of classes: {len(CLASSES)}\")\n",
    "\n",
    "# Create sample data.yaml (modify paths according to your dataset)\n",
    "data_yaml_path = create_data_yaml(\n",
    "    train_path=f\"{CONFIG['data_dir']}/train/images\",\n",
    "    val_path=f\"{CONFIG['data_dir']}/val/images\",\n",
    "    test_path=f\"{CONFIG['data_dir']}/test/images\",\n",
    "    classes=CLASSES,\n",
    "    save_path=f\"{CONFIG['data_dir']}/data.yaml\"\n",
    ")\n",
    "\n",
    "print(f\"Data configuration saved to: {data_yaml_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59cddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset validation\n",
    "try:\n",
    "    stats = preprocessor.validate_dataset(\n",
    "        images_dir=f\"{CONFIG['data_dir']}/train/images\",\n",
    "        labels_dir=f\"{CONFIG['data_dir']}/train/labels\"\n",
    "    )\n",
    "    \n",
    "    print(\"Dataset Statistics:\")\n",
    "    print(f\"  Total images: {stats['total_images']}\")\n",
    "    print(f\"  Total labels: {stats['total_labels']}\")\n",
    "    print(f\"  Missing labels: {stats['missing_labels']}\")\n",
    "    print(f\"  Missing images: {stats['missing_images']}\")\n",
    "    print(f\"  Class distribution: {stats['class_distribution']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Dataset validation failed: {e}\")\n",
    "    print(\"Make sure your dataset is properly organized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb7212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample annotations\n",
    "try:\n",
    "    preprocessor.visualize_annotations(\n",
    "        images_dir=f\"{CONFIG['data_dir']}/train/images\",\n",
    "        labels_dir=f\"{CONFIG['data_dir']}/train/labels\",\n",
    "        class_names=CLASSES,\n",
    "        num_samples=3\n",
    "    )\n",
    "    print(\"Sample annotations visualized!\")\n",
    "except Exception as e:\n",
    "    print(f\"Visualization failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca99859",
   "metadata": {},
   "source": [
    "## 3. Model Training\n",
    "\n",
    "Train your YOLOv8 model on the prepared dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c457fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize YOLOv8 detector\n",
    "detector = YOLOv8Detector(\n",
    "    model_size=CONFIG['model_size'],\n",
    "    device=CONFIG['device']\n",
    ")\n",
    "\n",
    "print(f\"Initialized YOLOv8 detector with {CONFIG['model_size']} on {CONFIG['device']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e33010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "training_config = {\n",
    "    'epochs': CONFIG['epochs'],\n",
    "    'batch': CONFIG['batch_size'],\n",
    "    'imgsz': CONFIG['img_size'],\n",
    "    'workers': 4,\n",
    "    'patience': 20,\n",
    "    'save': True,\n",
    "    'project': CONFIG['runs_dir'],\n",
    "    'name': f\"{CONFIG['model_size']}_training\",\n",
    "    'exist_ok': True,\n",
    "    'pretrained': True,\n",
    "    'optimizer': 'AdamW',\n",
    "    'lr0': 0.001,\n",
    "    'lrf': 0.01,\n",
    "    'momentum': 0.937,\n",
    "    'weight_decay': 0.0005,\n",
    "    'warmup_epochs': 3.0,\n",
    "    'warmup_momentum': 0.8,\n",
    "    'warmup_bias_lr': 0.1,\n",
    "    'box': 7.5,\n",
    "    'cls': 0.5,\n",
    "    'dfl': 1.5,\n",
    "    'hsv_h': 0.015,\n",
    "    'hsv_s': 0.7,\n",
    "    'hsv_v': 0.4,\n",
    "    'degrees': 0.0,\n",
    "    'translate': 0.1,\n",
    "    'scale': 0.5,\n",
    "    'shear': 0.0,\n",
    "    'perspective': 0.0,\n",
    "    'flipud': 0.0,\n",
    "    'fliplr': 0.5,\n",
    "    'mosaic': 1.0,\n",
    "    'mixup': 0.0,\n",
    "    'copy_paste': 0.0,\n",
    "}\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "for key, value in training_config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e346348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training (this may take a while)\n",
    "TRAIN_MODEL = False  # Set to True to start training\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    print(\"Starting model training...\")\n",
    "    results = detector.train(\n",
    "        data_yaml_path,\n",
    "        **training_config\n",
    "    )\n",
    "    print(\"Training completed!\")\n",
    "    print(f\"Best model saved at: {results.save_dir}/weights/best.pt\")\n",
    "else:\n",
    "    print(\"Training skipped. Set TRAIN_MODEL = True to start training.\")\n",
    "    print(\"Using pretrained model for demonstration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9385e3",
   "metadata": {},
   "source": [
    "## 4. Model Inference\n",
    "\n",
    "Test your trained model on sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9398ff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "model_path = f\"{CONFIG['runs_dir']}/train/{CONFIG['model_size']}_training/weights/best.pt\"\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    detector.load_model(model_path)\n",
    "    print(f\"Loaded trained model from {model_path}\")\n",
    "else:\n",
    "    print(f\"Trained model not found at {model_path}\")\n",
    "    print(\"Loading pretrained model for demonstration...\")\n",
    "    detector.load_model()  # Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f29da49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference on sample images\n",
    "test_images_dir = f\"{CONFIG['data_dir']}/test/images\"\n",
    "test_images = list(Path(test_images_dir).glob('*.jpg')) + list(Path(test_images_dir).glob('*.png'))\n",
    "\n",
    "if test_images:\n",
    "    # Select a few sample images\n",
    "    sample_images = test_images[:3]  # First 3 images\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(sample_images), figsize=(15, 5))\n",
    "    \n",
    "    for i, img_path in enumerate(sample_images):\n",
    "        # Run inference\n",
    "        results = detector.predict(\n",
    "            str(img_path),\n",
    "            conf=CONFIG['conf_threshold'],\n",
    "            iou=CONFIG['iou_threshold'],\n",
    "            save=False\n",
    "        )\n",
    "        \n",
    "        # Visualize results\n",
    "        for result in results:\n",
    "            img = result.plot()\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            if len(sample_images) == 1:\n",
    "                axes.imshow(img_rgb)\n",
    "            else:\n",
    "                axes[i].imshow(img_rgb)\n",
    "                axes[i].set_title(f\"Sample {i+1}\")\n",
    "                axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Inference completed on {len(sample_images)} sample images\")\n",
    "else:\n",
    "    print(f\"No test images found in {test_images_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd7963d",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation\n",
    "\n",
    "Evaluate your model's performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d04bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluator\n",
    "evaluator = YOLOEvaluator(model_path if os.path.exists(model_path) else None)\n",
    "\n",
    "print(\"Model evaluator initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a84ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation\n",
    "RUN_EVALUATION = False  # Set to True to run evaluation\n",
    "\n",
    "if RUN_EVALUATION:\n",
    "    print(\"Running model evaluation...\")\n",
    "    eval_results = evaluator.evaluate_on_dataset(\n",
    "        data_yaml_path,\n",
    "        conf=CONFIG['conf_threshold'],\n",
    "        iou=CONFIG['iou_threshold'],\n",
    "        save_dir=f\"{CONFIG['runs_dir']}/evaluation\"\n",
    "    )\n",
    "    \n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    print(f\"  mAP50: {eval_results['mAP50']:.4f}\")\n",
    "    print(f\"  mAP50-95: {eval_results['mAP50-95']:.4f}\")\n",
    "    print(f\"  Precision: {eval_results['precision']:.4f}\")\n",
    "    print(f\"  Recall: {eval_results['recall']:.4f}\")\n",
    "    \n",
    "    print(\"\\nPer-class Metrics:\")\n",
    "    for class_name, metrics in eval_results['class_metrics'].items():\n",
    "        print(f\"  {class_name}:\")\n",
    "        print(f\"    Precision: {metrics['precision']:.4f}\")\n",
    "        print(f\"    Recall: {metrics['recall']:.4f}\")\n",
    "        print(f\"    mAP50: {metrics['mAP50']:.4f}\")\n",
    "else:\n",
    "    print(\"Evaluation skipped. Set RUN_EVALUATION = True to run evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b139e4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance benchmarking\n",
    "RUN_BENCHMARK = False  # Set to True to run benchmarking\n",
    "\n",
    "if RUN_BENCHMARK and test_images:\n",
    "    print(\"Running performance benchmark...\")\n",
    "    benchmark_results = evaluator.benchmark_inference_speed(\n",
    "        test_images_dir,\n",
    "        num_runs=50\n",
    "    )\n",
    "    \n",
    "    print(\"\\nBenchmarking Results:\")\n",
    "    for batch_size, results in benchmark_results.items():\n",
    "        print(f\"  {batch_size}:\")\n",
    "        print(f\"    FPS: {results['fps']:.2f}\")\n",
    "        print(f\"    Avg time per inference: {results['avg_time_per_inference']*1000:.2f} ms\")\n",
    "else:\n",
    "    print(\"Benchmarking skipped. Set RUN_BENCHMARK = True to run benchmarking.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93527e5",
   "metadata": {},
   "source": [
    "## 6. Model Export and Deployment\n",
    "\n",
    "Export your model for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76beaf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model to different formats\n",
    "EXPORT_MODEL = False  # Set to True to export model\n",
    "\n",
    "if EXPORT_MODEL:\n",
    "    print(\"Exporting model...\")\n",
    "    \n",
    "    # Export to ONNX\n",
    "    onnx_path = detector.export_model(\n",
    "        format='onnx',\n",
    "        opset=11,\n",
    "        simplify=True\n",
    "    )\n",
    "    print(f\"ONNX model exported to: {onnx_path}\")\n",
    "    \n",
    "    # Export to TensorRT (if on NVIDIA GPU)\n",
    "    if torch.cuda.is_available():\n",
    "        trt_path = detector.export_model(\n",
    "            format='engine',\n",
    "            device='cuda'\n",
    "        )\n",
    "        print(f\"TensorRT model exported to: {trt_path}\")\n",
    "    \n",
    "    print(\"Model export completed!\")\n",
    "else:\n",
    "    print(\"Model export skipped. Set EXPORT_MODEL = True to export model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca88581",
   "metadata": {},
   "source": [
    "## 7. Interactive Testing\n",
    "\n",
    "Test your model with custom images or videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42e41a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive testing function\n",
    "def test_on_custom_image(image_path, conf_threshold=0.25, iou_threshold=0.6):\n",
    "    \"\"\"\n",
    "    Test model on a custom image\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to image\n",
    "        conf_threshold (float): Confidence threshold\n",
    "        iou_threshold (float): IoU threshold\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Testing on: {image_path}\")\n",
    "    \n",
    "    # Run inference\n",
    "    results = detector.predict(\n",
    "        image_path,\n",
    "        conf=conf_threshold,\n",
    "        iou=iou_threshold,\n",
    "        save=False\n",
    "    )\n",
    "    \n",
    "    # Display results\n",
    "    for result in results:\n",
    "        img = result.plot()\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        # Print detections\n",
    "        boxes = result.boxes\n",
    "        if boxes is not None:\n",
    "            print(f\"Detections: {len(boxes)}\")\n",
    "            for i, box in enumerate(boxes):\n",
    "                class_id = int(box.cls[0].cpu().numpy())\n",
    "                confidence = float(box.conf[0].cpu().numpy())\n",
    "                class_name = CLASSES[class_id] if class_id < len(CLASSES) else f\"class_{class_id}\"\n",
    "                print(f\"  {i+1}. {class_name}: {confidence:.2f}\")\n",
    "        else:\n",
    "            print(\"No detections\")\n",
    "\n",
    "# Example usage\n",
    "# test_on_custom_image(\"path/to/your/image.jpg\")\n",
    "print(\"Interactive testing function ready!\")\n",
    "print(\"Use: test_on_custom_image('path/to/image.jpg')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d25c151",
   "metadata": {},
   "source": [
    "## 8. Summary and Next Steps\n",
    "\n",
    "This notebook provides a complete workflow for YOLOv8 object detection:\n",
    "\n",
    "### What we've covered:\n",
    "1. **Setup and Configuration** - Environment setup and GPU detection\n",
    "2. **Data Preparation** - Dataset validation and visualization\n",
    "3. **Model Training** - Training configuration and execution\n",
    "4. **Model Inference** - Testing on sample images\n",
    "5. **Model Evaluation** - Performance metrics and benchmarking\n",
    "6. **Model Export** - Exporting for deployment\n",
    "7. **Interactive Testing** - Custom image testing\n",
    "\n",
    "### Next Steps:\n",
    "- Experiment with different model sizes (yolov8s, yolov8m, etc.)\n",
    "- Fine-tune hyperparameters for your specific use case\n",
    "- Implement custom data augmentation strategies\n",
    "- Deploy the model using the FastAPI service\n",
    "- Integrate with video streams for real-time detection\n",
    "\n",
    "### Key Files:\n",
    "- `src/yolov8_detector.py` - Main detection pipeline\n",
    "- `src/data_preprocessing.py` - Data preparation utilities\n",
    "- `src/api.py` - FastAPI service for deployment\n",
    "- `src/evaluation.py` - Model evaluation and benchmarking\n",
    "\n",
    "**Happy detecting! ðŸš€**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

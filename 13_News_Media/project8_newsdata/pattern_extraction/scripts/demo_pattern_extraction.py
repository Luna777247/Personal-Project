"""
Demo Script for Pattern-Based Extraction

This script demonstrates the pattern-based extraction system
for disaster information from Vietnamese news articles.
"""

import json
import time
from pathlib import Path
from typing import List, Dict, Any

from scripts.pattern_extractor import PatternBasedExtractor, ExtractionResult


def load_sample_articles() -> List[str]:
    """Load sample disaster news articles for testing"""
    sample_articles = [
        """
        B√£o s·ªë 12 g√¢y thi·ªát h·∫°i n·∫∑ng n·ªÅ t·∫°i c√°c t·ªânh mi·ªÅn Trung. Theo b√°o c√°o s∆° b·ªô,
        c∆°n b√£o ƒë√£ khi·∫øn 15 ng∆∞·ªùi thi·ªát m·∫°ng, 27 ng∆∞·ªùi b·ªã th∆∞∆°ng v√† 5 ng∆∞·ªùi m·∫•t t√≠ch.
        Thi·ªát h·∫°i v·ªÅ v·∫≠t ch·∫•t ∆∞·ªõc t√≠nh kho·∫£ng 1.200 t·ª∑ ƒë·ªìng, v·ªõi 150 cƒÉn nh√† b·ªã s·∫≠p
        ho√†n to√†n v√† h√†ng trƒÉm hecta l√∫a b·ªã ng·∫≠p √∫ng.

        T·∫°i t·ªânh Qu·∫£ng Nam, b√£o s·ªë 12 ƒë·ªï b·ªô v√†o l√∫c 14h30 ng√†y 15/11/2023,
        g√¢y m∆∞a l·ªõn li√™n t·ª•c trong 3 ng√†y. ƒê·ªôi c·ª©u h·ªô ƒë√£ tri·ªÉn khai ·ª©ng c·ª©u
        kh·∫©n c·∫•p t·∫°i c√°c khu v·ª±c b·ªã ·∫£nh h∆∞·ªüng n·∫∑ng nh·∫•t.
        """,

        """
        L≈© qu√©t x·∫£y ra t·∫°i huy·ªán M∆∞·ªùng Kh∆∞∆°ng, t·ªânh L√†o Cai v√†o s√°ng ng√†y 20/10/2023.
        Theo th√¥ng tin t·ª´ ·ª¶y ban nh√¢n d√¢n huy·ªán, tr·∫≠n l≈© ƒë√£ g√¢y thi·ªát h·∫°i nghi√™m tr·ªçng
        v·ªõi 8 ng∆∞·ªùi ch·∫øt, 12 ng∆∞·ªùi m·∫•t t√≠ch v√† h√†ng ch·ª•c ng√¥i nh√† b·ªã cu·ªën tr√¥i.

        Thi·ªát h·∫°i kinh t·∫ø ban ƒë·∫ßu ∆∞·ªõc t√≠nh 50 t·ª∑ ƒë·ªìng. Qu√¢n ƒë·ªôi v√† H·ªôi Ch·ªØ th·∫≠p ƒë·ªè
        ƒë√£ huy ƒë·ªông l·ª±c l∆∞·ª£ng c·ª©u h·ªô, t√¨m ki·∫øm ng∆∞·ªùi m·∫•t t√≠ch t·∫°i khu v·ª±c x·∫£y ra l≈©.
        """,

        """
        ƒê·ªông ƒë·∫•t m·∫°nh 6.5 ƒë·ªô Richter x·∫£y ra t·∫°i huy·ªán S√¨n H·ªì, t·ªânh Lai Ch√¢u
        v√†o l√∫c 22h45 ng√†y 18/6/2024. Theo Trung t√¢m B√°o tin ƒë·ªông ƒë·∫•t v√† C·∫£nh b√°o
        s√≥ng th·∫ßn, t√¢m ch·∫•n n·∫±m ·ªü ƒë·ªô s√¢u 10km v·ªõi b√°n k√≠nh ·∫£nh h∆∞·ªüng 50km.

        Hi·ªán ch∆∞a c√≥ th√¥ng tin v·ªÅ thi·ªát h·∫°i v·ªÅ ng∆∞·ªùi v√† t√†i s·∫£n. C√°c c∆° quan ch·ª©c nƒÉng
        ƒëang ki·ªÉm tra, ƒë√°nh gi√° m·ª©c ƒë·ªô ·∫£nh h∆∞·ªüng c·ªßa tr·∫≠n ƒë·ªông ƒë·∫•t.
        """,

        """
        M∆∞a l≈© k√©o d√†i t·∫°i c√°c t·ªânh T√¢y Nguy√™n g√¢y thi·ªát h·∫°i n·∫∑ng n·ªÅ.
        T·∫°i t·ªânh ƒê·∫Øk L·∫Øk, m∆∞a l·ªõn trong 5 ng√†y qua khi·∫øn 25 ng∆∞·ªùi ch·∫øt,
        40 ng∆∞·ªùi b·ªã th∆∞∆°ng v√† thi·ªát h·∫°i kinh t·∫ø l√™n t·ªõi 300 t·ª∑ ƒë·ªìng.

        H√†ng ngh√¨n hecta c√† ph√™ v√† h·ªì ti√™u b·ªã ng·∫≠p √∫ng, nhi·ªÅu tuy·∫øn ƒë∆∞·ªùng
        giao th√¥ng b·ªã s·∫°t l·ªü. Ch√≠nh quy·ªÅn ƒë·ªãa ph∆∞∆°ng ƒë√£ ch·ªâ ƒë·∫°o c√°c l·ª±c l∆∞·ª£ng
        ch·ª©c nƒÉng tri·ªÉn khai c·ª©u tr·ª£ kh·∫©n c·∫•p cho ng∆∞·ªùi d√¢n b·ªã ·∫£nh h∆∞·ªüng.
        """
    ]

    return sample_articles


def run_single_extraction_demo():
    """Demonstrate single text extraction"""
    print("=" * 60)
    print("PATTERN-BASED EXTRACTION DEMO")
    print("=" * 60)

    # Initialize extractor
    extractor = PatternBasedExtractor()

    # Load sample articles
    articles = load_sample_articles()

    print(f"\nLoaded {len(articles)} sample articles")
    print("\n" + "=" * 60)

    # Process each article
    for i, article in enumerate(articles, 1):
        print(f"\nüìÑ ARTICLE {i}")
        print("-" * 40)

        # Show first 200 characters of article
        preview = article.strip()[:200] + "..." if len(article.strip()) > 200 else article.strip()
        print(f"Preview: {preview}")
        print()

        # Extract entities
        start_time = time.time()
        entities = extractor.extract_entities(article)
        processing_time = time.time() - start_time

        print(f"‚è±Ô∏è  Processing time: {processing_time:.3f}s")
        print(f"üîç Found {len(entities)} entities:")
        print()

        # Group entities by type
        entities_by_type = {}
        for entity in entities:
            if entity.entity_type not in entities_by_type:
                entities_by_type[entity.entity_type] = []
            entities_by_type[entity.entity_type].append(entity)

        # Display entities by type
        for entity_type, type_entities in entities_by_type.items():
            type_info = extractor.config.get("entity_type_mapping", {}).get(entity_type, {})
            display_name = type_info.get("display_name", entity_type)

            print(f"  {display_name} ({entity_type}):")
            for entity in type_entities:
                confidence_pct = int(entity.confidence * 100)
                print(f"    ‚Ä¢ '{entity.text}' (confidence: {confidence_pct}%)")
                if entity.context:
                    # Show context with match highlighted
                    context_preview = entity.context[:100] + "..." if len(entity.context) > 100 else entity.context
                    print(f"      Context: {context_preview}")
            print()

        print("-" * 40)


def run_batch_extraction_demo():
    """Demonstrate batch processing"""
    print("\n" + "=" * 60)
    print("BATCH EXTRACTION DEMO")
    print("=" * 60)

    # Initialize extractor
    extractor = PatternBasedExtractor()

    # Load sample articles
    articles = load_sample_articles()

    print(f"\nProcessing {len(articles)} articles in batch mode...")

    # Process batch
    start_time = time.time()
    results = extractor.extract_from_texts(articles, batch_size=2)
    total_time = time.time() - start_time

    print(".2f")
    print(f"üìä Total entities extracted: {sum(len(result.entities) for result in results)}")

    # Show summary statistics
    entity_type_counts = {}
    total_confidences = []

    for result in results:
        for entity in result.entities:
            entity_type_counts[entity.entity_type] = entity_type_counts.get(entity.entity_type, 0) + 1
            total_confidences.append(entity.confidence)

    print("\nüìà Entity Type Distribution:")
    for entity_type, count in sorted(entity_type_counts.items()):
        type_info = extractor.config.get("entity_type_mapping", {}).get(entity_type, {})
        display_name = type_info.get("display_name", entity_type)
        print(f"  ‚Ä¢ {display_name}: {count}")

    if total_confidences:
        avg_confidence = sum(total_confidences) / len(total_confidences)
        print(".1f")
    # Save results
    output_path = Path(__file__).parent.parent / "data" / "batch_extraction_results.json"
    extractor.save_results(results, str(output_path))
    print(f"\nüíæ Results saved to: {output_path}")


def run_pattern_analysis_demo():
    """Demonstrate pattern statistics and analysis"""
    print("\n" + "=" * 60)
    print("PATTERN ANALYSIS DEMO")
    print("=" * 60)

    extractor = PatternBasedExtractor()

    # Get pattern statistics
    stats = extractor.get_pattern_stats()

    print(f"\nüìä Pattern Statistics:")
    print(f"  ‚Ä¢ Total patterns: {stats['total_patterns']}")
    print(f"  ‚Ä¢ Entity types: {len(stats['entity_types'])}")
    print(f"    {', '.join(stats['entity_types'])}")

    print("\nüìÇ Pattern Categories:")
    for category, count in stats['pattern_categories'].items():
        print(f"  ‚Ä¢ {category}: {count} patterns")

    # Show sample patterns
    print("\nüîç Sample Patterns:")
    from config.patterns import PATTERN_CATEGORIES

    for category_name, patterns in PATTERN_CATEGORIES.items():
        if category_name != "all" and patterns:
            print(f"\n  {category_name.upper()}:")
            for pattern in patterns[:2]:  # Show first 2 patterns per category
                print(f"    ‚Ä¢ {pattern.name}: {pattern.pattern}")
                if pattern.examples:
                    print(f"      Examples: {', '.join(pattern.examples[:2])}")


def run_custom_pattern_demo():
    """Demonstrate custom pattern creation and testing"""
    print("\n" + "=" * 60)
    print("CUSTOM PATTERN DEMO")
    print("=" * 60)

    # Create custom extractor with additional patterns
    custom_config = {
        "min_confidence": 0.7,
        "max_matches_per_type": 3
    }

    extractor = PatternBasedExtractor(config=custom_config)

    # Test text with various disaster information
    test_text = """
    Theo b√°o c√°o c·ªßa B·ªô N√¥ng nghi·ªáp v√† Ph√°t tri·ªÉn n√¥ng th√¥n, b√£o s·ªë 8
    ƒë√£ g√¢y thi·ªát h·∫°i n·∫∑ng n·ªÅ t·∫°i 8 t·ªânh mi·ªÅn Trung v·ªõi 45 ng∆∞·ªùi ch·∫øt,
    120 ng∆∞·ªùi b·ªã th∆∞∆°ng v√† thi·ªát h·∫°i kinh t·∫ø l√™n t·ªõi 2.500 t·ª∑ ƒë·ªìng.

    T·∫°i t·ªânh Qu·∫£ng B√¨nh, gi√≥ b√£o t·ªëc ƒë·ªô 150km/h khi·∫øn 200 cƒÉn nh√† b·ªã t·ªëc m√°i,
    50 c√¢y c·∫ßu b·ªã s·∫≠p v√† h√†ng ngh√¨n hecta l√∫a b·ªã ng·∫≠p. ƒê·ªôi c·ª©u h·ªô ƒë√£
    tri·ªÉn khai ·ª©ng c·ª©u t·∫°i khu v·ª±c b·ªã ·∫£nh h∆∞·ªüng t·ª´ ng√†y 28/9/2023.
    """

    print("Test Text:")
    print(test_text.strip())
    print("\n" + "-" * 60)

    # Extract entities
    entities = extractor.extract_entities(test_text)

    print(f"Found {len(entities)} entities with custom configuration:")

    for entity in entities:
        confidence_pct = int(entity.confidence * 100)
        print(f"  ‚Ä¢ {entity.entity_type}: '{entity.text}' ({confidence_pct}%)")


def main():
    """Main demo function"""
    print("üöÄ Starting Pattern-Based Extraction Demo")
    print("This demo showcases rule-based extraction for disaster information")
    print()

    try:
        # Run different demo modes
        run_single_extraction_demo()
        run_batch_extraction_demo()
        run_pattern_analysis_demo()
        run_custom_pattern_demo()

        print("\n" + "=" * 60)
        print("‚úÖ All demos completed successfully!")
        print("=" * 60)

    except Exception as e:
        print(f"\n‚ùå Error during demo: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
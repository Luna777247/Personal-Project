"""
Demo Script for LLM-Based Disaster Information Extraction

This script demonstrates the Large Language Model-based extraction system
for disaster information from Vietnamese news articles.
"""

import json
import time
from pathlib import Path
from typing import List, Dict, Any

from scripts.llm_extractor import LLMExtractor, LLMExtractionResult


def load_sample_articles() -> List[str]:
    """Load sample disaster news articles for testing"""
    sample_articles = [
        """
        B√£o s·ªë 12 g√¢y thi·ªát h·∫°i n·∫∑ng n·ªÅ t·∫°i c√°c t·ªânh mi·ªÅn Trung. Theo b√°o c√°o s∆° b·ªô,
        c∆°n b√£o ƒë√£ khi·∫øn 15 ng∆∞·ªùi thi·ªát m·∫°ng, 27 ng∆∞·ªùi b·ªã th∆∞∆°ng v√† 5 ng∆∞·ªùi m·∫•t t√≠ch.
        Thi·ªát h·∫°i v·ªÅ v·∫≠t ch·∫•t ∆∞·ªõc t√≠nh kho·∫£ng 1.200 t·ª∑ ƒë·ªìng, v·ªõi 150 cƒÉn nh√† b·ªã s·∫≠p
        ho√†n to√†n v√† h√†ng trƒÉm hecta l√∫a b·ªã ng·∫≠p √∫ng.

        T·∫°i t·ªânh Qu·∫£ng Nam, b√£o s·ªë 12 ƒë·ªï b·ªô v√†o l√∫c 14h30 ng√†y 15/11/2023,
        g√¢y m∆∞a l·ªõn li√™n t·ª•c trong 3 ng√†y. ƒê·ªôi c·ª©u h·ªô ƒë√£ tri·ªÉn khai ·ª©ng c·ª©u
        kh·∫©n c·∫•p t·∫°i c√°c khu v·ª±c b·ªã ·∫£nh h∆∞·ªüng n·∫∑ng nh·∫•t.
        """,

        """
        L≈© qu√©t x·∫£y ra t·∫°i huy·ªán M∆∞·ªùng Kh∆∞∆°ng, t·ªânh L√†o Cai v√†o s√°ng ng√†y 20/10/2023.
        Theo th√¥ng tin t·ª´ ·ª¶y ban nh√¢n d√¢n huy·ªán, tr·∫≠n l≈© ƒë√£ g√¢y thi·ªát h·∫°i nghi√™m tr·ªçng
        v·ªõi 8 ng∆∞·ªùi ch·∫øt, 12 ng∆∞·ªùi m·∫•t t√≠ch v√† h√†ng ch·ª•c ng√¥i nh√† b·ªã cu·ªën tr√¥i.

        Thi·ªát h·∫°i kinh t·∫ø ban ƒë·∫ßu ∆∞·ªõc t√≠nh 50 t·ª∑ ƒë·ªìng. Qu√¢n ƒë·ªôi v√† H·ªôi Ch·ªØ th·∫≠p ƒë·ªè
        ƒë√£ huy ƒë·ªông l·ª±c l∆∞·ª£ng c·ª©u h·ªô, t√¨m ki·∫øm ng∆∞·ªùi m·∫•t t√≠ch t·∫°i khu v·ª±c x·∫£y ra l≈©.
        """,

        """
        ƒê·ªông ƒë·∫•t m·∫°nh 6.5 ƒë·ªô Richter x·∫£y ra t·∫°i huy·ªán S√¨n H·ªì, t·ªânh Lai Ch√¢u
        v√†o l√∫c 22h45 ng√†y 18/6/2024. Theo Trung t√¢m B√°o tin ƒë·ªông ƒë·∫•t v√† C·∫£nh b√°o
        s√≥ng th·∫ßn, t√¢m ch·∫•n n·∫±m ·ªü ƒë·ªô s√¢u 10km v·ªõi b√°n k√≠nh ·∫£nh h∆∞·ªüng 50km.

        Hi·ªán ch∆∞a c√≥ th√¥ng tin v·ªÅ thi·ªát h·∫°i v·ªÅ ng∆∞·ªùi v√† t√†i s·∫£n. C√°c c∆° quan ch·ª©c nƒÉng
        ƒëang ki·ªÉm tra, ƒë√°nh gi√° m·ª©c ƒë·ªô ·∫£nh h∆∞·ªüng c·ªßa tr·∫≠n ƒë·ªông ƒë·∫•t.
        """
    ]

    return sample_articles


def run_single_extraction_demo():
    """Demonstrate single text extraction with different models"""
    print("=" * 70)
    print("LLM-BASED DISASTER EXTRACTION DEMO")
    print("=" * 70)

    # Initialize extractor
    try:
        extractor = LLMExtractor()
    except ValueError as e:
        print(f"‚ùå Initialization failed: {e}")
        print("Please set API keys for at least one LLM provider:")
        print("  - OPENAI_API_KEY for GPT models")
        print("  - ANTHROPIC_API_KEY for Claude models")
        print("  - GROQ_API_KEY for Llama models")
        return

    # Load sample articles
    articles = load_sample_articles()

    print(f"\nLoaded {len(articles)} sample articles")
    print(f"Available models: {', '.join(extractor.available_models)}")
    print("\n" + "=" * 70)

    # Test different models if available
    models_to_test = ["gpt-3.5-turbo", "llama3-8b", "claude-3-haiku"]
    available_test_models = [m for m in models_to_test if m in extractor.available_models]

    if not available_test_models:
        available_test_models = [extractor.available_models[0]]  # Use first available

    # Process first article with different models
    test_article = articles[0]
    print("üì∞ TESTING ARTICLE:")
    print("-" * 50)
    preview = test_article.strip()[:300] + "..." if len(test_article.strip()) > 300 else test_article.strip()
    print(preview)
    print("\n" + "=" * 70)

    for model in available_test_models:
        print(f"\nü§ñ MODEL: {model.upper()}")
        print("-" * 30)

        try:
            # Extract information
            start_time = time.time()
            result = extractor.extract_disaster_info(test_article, model=model)
            processing_time = time.time() - start_time

            print(f"‚è±Ô∏è  Processing Time: {processing_time:.2f}s")
            print(f"üí∞ Cost: ${result.cost_estimate:.4f}")
            print(f"üéØ Confidence: {result.confidence_score:.2f}")
            print()

            # Display extracted information
            info = result.extracted_info
            if "error" not in info:
                print("üìã EXTRACTED INFORMATION:")
                print(f"  ‚Ä¢ Type: {info.get('type', 'N/A')}")
                print(f"  ‚Ä¢ Location: {info.get('location', 'N/A')}")
                print(f"  ‚Ä¢ Time: {info.get('time', 'N/A')}")
                print(f"  ‚Ä¢ Severity: {info.get('severity', 'N/A')}")
                print(f"  ‚Ä¢ Damage: {info.get('damage', 'N/A')}")
                print(f"  ‚Ä¢ Deaths: {info.get('deaths', 'N/A')}")
                print(f"  ‚Ä¢ Injured: {info.get('injured', 'N/A')}")
                print(f"  ‚Ä¢ Missing: {info.get('missing', 'N/A')}")
                print(f"  ‚Ä¢ Forecast: {info.get('forecast', 'N/A')}")

                if info.get('organizations'):
                    print(f"  ‚Ä¢ Organizations: {', '.join(info['organizations'])}")
            else:
                print(f"‚ùå Extraction error: {info.get('error', 'Unknown error')}")

        except Exception as e:
            print(f"‚ùå Model {model} failed: {str(e)}")

        print("-" * 30)


def run_batch_extraction_demo():
    """Demonstrate batch processing"""
    print("\n" + "=" * 70)
    print("BATCH EXTRACTION DEMO")
    print("=" * 70)

    try:
        extractor = LLMExtractor()
    except ValueError as e:
        print(f"‚ùå Initialization failed: {e}")
        return

    # Load sample articles
    articles = load_sample_articles()

    print(f"\nProcessing {len(articles)} articles in batch mode...")
    print(f"Using model: {extractor.config['default_model']}")

    # Process batch
    start_time = time.time()
    results = extractor.extract_from_texts(articles, batch_size=2)
    total_time = time.time() - start_time

    print(f"‚è±Ô∏è  Total Time: {total_time:.2f}s")
    print(f"üìä Total extractions: {len(results)}")

    # Calculate statistics
    successful = sum(1 for r in results if "error" not in r.extracted_info)
    total_cost = sum(r.cost_estimate for r in results)
    avg_confidence = sum(r.confidence_score for r in results) / len(results) if results else 0

    print(f"‚úÖ Successful: {successful}/{len(results)}")
    print(f"üí∞ Total Cost: ${total_cost:.2f}")
    print(f"üéØ Avg Confidence: {avg_confidence:.3f}")

    # Show summary for each article
    print("\nüìã EXTRACTION SUMMARY:")
    for i, result in enumerate(results, 1):
        status = "‚úÖ" if "error" not in result.extracted_info else "‚ùå"
        info = result.extracted_info
        disaster_type = info.get('type', 'N/A') if "error" not in info else "ERROR"
        location = info.get('location', 'N/A') if "error" not in info else ""
        deaths = info.get('deaths', 'N/A') if "error" not in info else ""

        print(f"  {status} Article {i}: {disaster_type} | {location} | Deaths: {deaths}")

    # Save results
    output_path = Path(__file__).parent.parent / "data" / "batch_llm_extraction_results.json"
    extractor.save_results(results, str(output_path))
    print(f"\nüíæ Results saved to: {output_path}")


def run_model_comparison_demo():
    """Compare different models on the same text"""
    print("\n" + "=" * 70)
    print("MODEL COMPARISON DEMO")
    print("=" * 70)

    try:
        extractor = LLMExtractor()
    except ValueError as e:
        print(f"‚ùå Initialization failed: {e}")
        return

    # Test article
    test_article = """
    B√£o Noru ƒë·ªï b·ªô v√†o Ph√∫ Y√™n s√°ng 28/9, g√¢y m∆∞a l·ªõn tr√™n di·ªán r·ªông.
    Theo Ban Ch·ªâ huy Ph√≤ng ch·ªëng thi√™n tai t·ªânh Ph√∫ Y√™n, b√£o ƒë√£ l√†m
    2 ng∆∞·ªùi ch·∫øt, 5 ng∆∞·ªùi b·ªã th∆∞∆°ng, t·ªëc m√°i 50 cƒÉn nh√† v√† l√†m ng·∫≠p
    200 ha l√∫a. T·ªïng thi·ªát h·∫°i ban ƒë·∫ßu ∆∞·ªõc t√≠nh 80 t·ª∑ ƒë·ªìng.

    √îng Nguy·ªÖn VƒÉn B√© - Ph√≥ Ch·ªß t·ªãch UBND t·ªânh Ph√∫ Y√™n cho bi·∫øt:
    "B√£o Noru l√† c∆°n b√£o r·∫•t m·∫°nh, t·ªëc ƒë·ªô gi√≥ gi·∫≠t tr√™n 40m/s.
    C√°c l·ª±c l∆∞·ª£ng ch·ª©c nƒÉng ƒë√£ tri·ªÉn khai ·ª©ng c·ª©u k·ªãp th·ªùi."
    """

    print("üì∞ TEST ARTICLE:")
    print("-" * 50)
    print(test_article.strip())
    print("\n" + "=" * 70)

    # Test available models
    models_to_compare = [m for m in extractor.available_models if m in
                        ["gpt-3.5-turbo", "gpt-4", "claude-3-haiku", "llama3-8b"]]

    if not models_to_compare:
        models_to_compare = extractor.available_models[:3]  # Use first 3 available

    results = {}

    print("üèÅ COMPARING MODELS:")
    print("-" * 50)

    for model in models_to_compare:
        print(f"\nü§ñ {model.upper()}:")
        try:
            result = extractor.extract_disaster_info(test_article, model=model)
            results[model] = result

            info = result.extracted_info
            if "error" not in info:
                print(f"  ‚è±Ô∏è  Time: {result.processing_time:.2f}s | üí∞ Cost: ${result.cost_estimate:.4f}")
                print(f"  ‚Ä¢ Type: {info.get('type', 'N/A')}")
                print(f"  ‚Ä¢ Location: {info.get('location', 'N/A')}")
                print(f"  ‚Ä¢ Deaths: {info.get('deaths', 'N/A')}")
                print(f"  ‚Ä¢ Damage: {info.get('damage', 'N/A')}")
            else:
                print(f"  ‚ùå Error: {info.get('error', 'Unknown')}")

        except Exception as e:
            print(f"  ‚ùå Failed: {str(e)}")

    # Comparison summary
    print("\nüìä COMPARISON SUMMARY:")
    print("-" * 50)
    print(f"{'Model':<15} {'Cost':<10} {'Confidence':<12} {'Deaths':<8} {'Location':<15}")
    print("-" * 50)

    for model, result in results.items():
        info = result.extracted_info
        if "error" not in info:
            deaths = info.get('deaths', 'N/A')
            location = info.get('location', 'N/A')
            confidence = result.confidence_score
            cost = result.cost_estimate
            time_taken = result.processing_time

            print(f"{model:<15} ${cost:<9.4f} {confidence:<11.2f} {deaths:<7} {location:<15}")


def run_metrics_demo():
    """Show extraction metrics and performance"""
    print("\n" + "=" * 70)
    print("EXTRACTION METRICS DEMO")
    print("=" * 70)

    try:
        extractor = LLMExtractor()
    except ValueError as e:
        print(f"‚ùå Initialization failed: {e}")
        return

    # Get current metrics
    metrics = extractor.get_metrics()

    print("üìä CURRENT METRICS:")
    print("-" * 50)
    print(f"Total Requests: {metrics['total_requests']}")
    print(f"Success Rate: {metrics['success_rate']:.1%}")
    print(f"üí∞ Total Cost: ${metrics['total_cost']:.2f}")
    print(f"‚è±Ô∏è  Avg Processing Time: {metrics['avg_processing_time']:.2f}s")
    print(f"üíæ Cache Hit Rate: {metrics['cache_hit_rate']:.1f}")
    print(f"ü§ñ Available Models: {metrics['available_models_count']}")

    print("\nü§ñ AVAILABLE MODELS:")
    for model in metrics['available_models']:
        print(f"  ‚Ä¢ {model}")

    # Test with a few extractions to show metrics change
    print("\nüîÑ RUNNING SAMPLE EXTRACTIONS...")
    articles = load_sample_articles()[:2]  # Just 2 for demo

    for i, article in enumerate(articles, 1):
        print(f"  Processing article {i}...")
        extractor.extract_disaster_info(article)

    # Show updated metrics
    updated_metrics = extractor.get_metrics()
    print("\nüìà UPDATED METRICS:")
    print("-" * 50)
    print(f"Total Requests: {updated_metrics['total_requests']}")
    print(f"Success Rate: {updated_metrics['success_rate']:.1%}")
    print(f"üí∞ Total Cost: ${updated_metrics['total_cost']:.2f}")
    print(f"‚è±Ô∏è  Avg Processing Time: {updated_metrics['avg_processing_time']:.2f}s")
    print(f"üíæ Cache Hit Rate: {updated_metrics['cache_hit_rate']:.1f}")
    print(f"ü§ñ Available Models: {updated_metrics['available_models_count']}")


def run_custom_prompt_demo():
    """Demonstrate custom prompt usage"""
    print("\n" + "=" * 70)
    print("CUSTOM PROMPT DEMO")
    print("=" * 70)

    try:
        extractor = LLMExtractor()
    except ValueError as e:
        print(f"‚ùå Initialization failed: {e}")
        return

    # Test article
    test_article = """
    H·∫°n h√°n k√©o d√†i t·∫°i c√°c t·ªânh T√¢y Nguy√™n khi·∫øn h√†ng ngh√¨n hecta c√† ph√™
    b·ªã kh√¥ h·∫°n. Theo S·ªü N√¥ng nghi·ªáp t·ªânh ƒê·∫Øk L·∫Øk, h·∫°n h√°n nƒÉm 2024
    nghi√™m tr·ªçng h∆°n m·ªçi nƒÉm, ·∫£nh h∆∞·ªüng ƒë·∫øn 50.000 h·ªô d√¢n.
    """

    print("üì∞ TEST ARTICLE:")
    print("-" * 50)
    print(test_article.strip())
    print("\n" + "=" * 70)

    # Test different prompt types
    prompt_types = ["basic", "detailed", "full"]

    for prompt_type in prompt_types:
        print(f"\nüìù PROMPT TYPE: {prompt_type.upper()}")
        print("-" * 30)

        try:
            result = extractor.extract_disaster_info(
                test_article,
                prompt_type=prompt_type
            )

            print(".2f"            print(f"üí∞ Cost: ${result.cost_estimate:.4f}")

            info = result.extracted_info
            if "error" not in info:
                # Show key fields
                key_fields = ['type', 'location', 'time', 'damage', 'deaths']
                for field in key_fields:
                    value = info.get(field, 'N/A')
                    print(f"  ‚Ä¢ {field}: {value}")
            else:
                print(f"‚ùå Error: {info.get('error', 'Unknown')}")

        except Exception as e:
            print(f"‚ùå Failed: {str(e)}")

        print("-" * 30)


def main():
    """Main demo function"""
    print("üöÄ Starting LLM-Based Extraction Demo")
    print("This demo showcases Large Language Model-based extraction for disaster information")
    print()

    try:
        # Run different demo modes
        run_single_extraction_demo()
        run_batch_extraction_demo()
        run_model_comparison_demo()
        run_metrics_demo()
        run_custom_prompt_demo()

        print("\n" + "=" * 70)
        print("‚úÖ All demos completed successfully!")
        print("=" * 70)

    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Interrupted by user")
    except Exception as e:
        print(f"\n‚ùå Error during demo: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()